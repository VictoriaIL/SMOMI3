{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6NaAD8zpv2Yv","colab_type":"code","outputId":"9ee46782-2096-44eb-e6f6-2d0094326b4d","executionInfo":{"status":"ok","timestamp":1591567486250,"user_tz":-180,"elapsed":19245,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c3bJlWt3Vq_G","colab_type":"code","outputId":"ee490b0c-abc8-4263-ee6e-9b32c25daf5c","executionInfo":{"status":"ok","timestamp":1591567594115,"user_tz":-180,"elapsed":109542,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":860}},"source":["!pip3 uninstall tensorflow \n","!pip3 install tensorflow-gpu==1.14"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.2.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.2.0\n","Collecting tensorflow-gpu==1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n","\u001b[K     |████████████████████████████████| 377.0MB 39kB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.29.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 44.5MB/s \n","\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 60.0MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (47.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.0)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bFBz8AdxWlQB","colab_type":"code","outputId":"d5d96f8a-b040-4d43-cb39-7f843bcdb70b","executionInfo":{"status":"ok","timestamp":1591567595889,"user_tz":-180,"elapsed":100613,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/СМОМИ/Лаба 3\")\n","!ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":[" images  'lab3(3)(1).ipynb'   lab3.ipynb   logs  'model (1).h5'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IbvI6OmOimd9","colab_type":"code","outputId":"133f8185-4b1e-410e-b236-4548c8bd18b8","executionInfo":{"status":"ok","timestamp":1591567597174,"user_tz":-180,"elapsed":99783,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":440}},"source":["import argparse\n","import glob\n","import numpy as np\n","import tensorflow as tf\n","import time\n","from tensorflow.python import keras as keras\n","from tensorflow.python.keras.callbacks import LearningRateScheduler"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"j1q2xvl1iqlf","colab_type":"code","colab":{}},"source":["LOG_DIR = 'logs'\n","SHUFFLE_BUFFER = 10\n","BATCH_SIZE = 8\n","NUM_CLASSES = 2\n","PARALLEL_CALLS=4\n","RESIZE_TO = 224\n","TRAINSET_SIZE = 5216\n","VALSET_SIZE=624"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9mY1J2SjKYX","colab_type":"code","colab":{}},"source":["def parse_proto_example(proto):\n","    keys_to_features = {\n","        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n","        'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64))\n","    }\n","    example = tf.parse_single_example(proto, keys_to_features)\n","    example['image'] = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n","    example['image'] = tf.image.convert_image_dtype(example['image'], dtype=tf.float32)\n","    example['image'] = tf.image.resize_images(example['image'], tf.constant([RESIZE_TO, RESIZE_TO]))\n","    return example['image'], example['image/class/label']\n","\n","    \n","def normalize(image, label):\n","    return tf.image.per_image_standardization(image), label\n","\n","\n","def resize(image, label):\n","    return tf.image.resize_images(image, tf.constant([RESIZE_TO, RESIZE_TO])), label\n","    \n","def create_dataset(filenames, batch_size):\n","    \"\"\"Create dataset from tfrecords file\n","    :tfrecords_files: Mask to collect tfrecords file of dataset\n","    :returns: tf.data.Dataset\n","    \"\"\"\n","    return tf.data.TFRecordDataset(filenames) \\\n","        .map(parse_proto_example) \\\n","        .map(resize) \\\n","        .map(normalize) \\\n","        .map(resize) \\\n","        .shuffle(buffer_size=5 * batch_size) \\\n","        .repeat() \\\n","        .batch(batch_size) \\\n","        .prefetch(2 * batch_size)\n","\n","class Validation(tf.keras.callbacks.Callback):\n","    def __init__(self, log_dir, validation_files, batch_size):\n","        self.log_dir = log_dir\n","        self.validation_files = validation_files\n","        self.batch_size = batch_size\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        print('The average loss for epoch {} is {:7.2f} '.format(\n","            epoch, logs['loss']\n","        ))\n","\n","        validation_dataset = create_dataset(self.validation_files, self.batch_size)\n","        validation_images, validation_labels = validation_dataset.make_one_shot_iterator().get_next()\n","        validation_labels = tf.one_hot(validation_labels, NUM_CLASSES)\n","\n","        result = self.model.evaluate(\n","            validation_images,\n","            validation_labels,\n","            steps=int(np.ceil(VALSET_SIZE / float(BATCH_SIZE)))\n","        )\n","        callback = tf.keras.callbacks.TensorBoard(log_dir=self.log_dir, update_freq='epoch', batch_size=self.batch_size)\n","\n","        callback.set_model(self.model)\n","        callback.on_epoch_end(epoch, {\n","            'val_' + self.model.metrics_names[i]: v for i, v in enumerate(result)\n","        })"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKsWQDa0kKiT","colab_type":"code","colab":{}},"source":["def build_model():\n","    return tf.keras.models.Sequential([\n","        tf.keras.layers.Input(shape=(224,224,3)),\n","        tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","\n","        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","\n","        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2)),\n","\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(units=4096,activation=\"relu\"),\n","        tf.keras.layers.Dense(units=4096,activation=\"relu\"),  \n","        tf.keras.layers.Dense(NUM_CLASSES, activation=tf.keras.activations.softmax)\n","    ])\n","     "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZ-XYT6ZkShb","colab_type":"code","colab":{}},"source":["train_path = './images/train*'\n","test_path = './images/test*'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQRlHXcikrft","colab_type":"code","outputId":"975bd195-701f-4ca4-9ee6-a088fa659925","executionInfo":{"status":"ok","timestamp":1591575542818,"user_tz":-180,"elapsed":8025255,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def main():\n","    train_dataset = create_dataset(glob.glob(train_path), BATCH_SIZE)\n","    train_images, train_labels = train_dataset.make_one_shot_iterator().get_next()\n","    train_labels = tf.one_hot(train_labels, NUM_CLASSES)\n","\n","    model = build_model()\n","\n","    model.compile(\n","        optimizer=keras.optimizers.sgd(lr=0.0000003, momentum=0.9),\n","        loss=tf.keras.losses.categorical_crossentropy,\n","        metrics=[tf.keras.metrics.categorical_accuracy],\n","        target_tensors=[train_labels]\n","    )\n","\n","    log_dir='{}/xray-{}'.format(LOG_DIR, time.time())\n","    model.fit(\n","        (train_images, train_labels),\n","        epochs=100, \n","        steps_per_epoch=int(np.ceil(TRAINSET_SIZE / float(BATCH_SIZE))),\n","        callbacks=[\n","            tf.keras.callbacks.TensorBoard(log_dir),\n","            Validation(log_dir, validation_files=glob.glob(test_path), batch_size=BATCH_SIZE)\n","        ]\n","    )\n","\n","\n","if __name__ == '__main__':\n","    main()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py:1514: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","WARNING:tensorflow:From <ipython-input-9-2a25e6270c45>:3: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Epoch 1/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1094 - categorical_accuracy: 0.8427The average loss for epoch 0 is    0.11 \n","78/78 [==============================] - 15s 189ms/step - loss: 0.1192 - categorical_accuracy: 0.8285\n","652/652 [==============================] - 92s 141ms/step - loss: 0.1092 - categorical_accuracy: 0.8430\n","Epoch 2/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1644 - categorical_accuracy: 0.7634The average loss for epoch 1 is    0.16 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0011 - categorical_accuracy: 0.9984\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1641 - categorical_accuracy: 0.7638\n","Epoch 3/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1092 - categorical_accuracy: 0.8406The average loss for epoch 2 is    0.11 \n","78/78 [==============================] - 13s 165ms/step - loss: 0.3247 - categorical_accuracy: 0.5369\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1090 - categorical_accuracy: 0.8409\n","Epoch 4/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1099 - categorical_accuracy: 0.8109The average loss for epoch 3 is    0.11 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.8542\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1097 - categorical_accuracy: 0.8110\n","Epoch 5/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1090 - categorical_accuracy: 0.5603The average loss for epoch 4 is    0.11 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0155 - categorical_accuracy: 0.3365\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1089 - categorical_accuracy: 0.5600\n","Epoch 6/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1740 - categorical_accuracy: 0.3297The average loss for epoch 5 is    0.17 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0155 - categorical_accuracy: 0.0304\n","652/652 [==============================] - 81s 125ms/step - loss: 0.1742 - categorical_accuracy: 0.3299\n","Epoch 7/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1088 - categorical_accuracy: 0.1772The average loss for epoch 6 is    0.11 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.2206 - categorical_accuracy: 0.3205\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1087 - categorical_accuracy: 0.1771\n","Epoch 8/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1219 - categorical_accuracy: 0.1813The average loss for epoch 7 is    0.12 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1217 - categorical_accuracy: 0.1810\n","Epoch 9/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1087 - categorical_accuracy: 0.1580The average loss for epoch 8 is    0.11 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1085 - categorical_accuracy: 0.1578\n","Epoch 10/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1612 - categorical_accuracy: 0.2335The average loss for epoch 9 is    0.16 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.1283 - categorical_accuracy: 0.1859\n","652/652 [==============================] - 83s 127ms/step - loss: 0.1620 - categorical_accuracy: 0.2347\n","Epoch 11/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1085 - categorical_accuracy: 0.1573The average loss for epoch 10 is    0.11 \n","78/78 [==============================] - 11s 147ms/step - loss: 0.0995 - categorical_accuracy: 0.1442\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1083 - categorical_accuracy: 0.1570\n","Epoch 12/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1360 - categorical_accuracy: 0.1972The average loss for epoch 11 is    0.14 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1358 - categorical_accuracy: 0.1969\n","Epoch 13/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1084 - categorical_accuracy: 0.1573The average loss for epoch 12 is    0.11 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1082 - categorical_accuracy: 0.1570\n","Epoch 14/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1462 - categorical_accuracy: 0.2124The average loss for epoch 13 is    0.15 \n","78/78 [==============================] - 12s 151ms/step - loss: 0.2493 - categorical_accuracy: 0.3622\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1471 - categorical_accuracy: 0.2136\n","Epoch 15/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1082 - categorical_accuracy: 0.1573The average loss for epoch 14 is    0.11 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0033 - categorical_accuracy: 0.0048\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1080 - categorical_accuracy: 0.1570\n","Epoch 16/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1471 - categorical_accuracy: 0.2139The average loss for epoch 15 is    0.15 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1468 - categorical_accuracy: 0.2136\n","Epoch 17/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1080 - categorical_accuracy: 0.1573The average loss for epoch 16 is    0.11 \n","78/78 [==============================] - 11s 136ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 76s 117ms/step - loss: 0.1079 - categorical_accuracy: 0.1570\n","Epoch 18/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1313 - categorical_accuracy: 0.1912The average loss for epoch 17 is    0.13 \n","78/78 [==============================] - 12s 159ms/step - loss: 0.3697 - categorical_accuracy: 0.5385\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1322 - categorical_accuracy: 0.1925\n","Epoch 19/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1079 - categorical_accuracy: 0.1573The average loss for epoch 18 is    0.11 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1077 - categorical_accuracy: 0.1570\n","Epoch 20/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1471 - categorical_accuracy: 0.2145The average loss for epoch 19 is    0.15 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1468 - categorical_accuracy: 0.2141\n","Epoch 21/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1078 - categorical_accuracy: 0.1573The average loss for epoch 20 is    0.11 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1076 - categorical_accuracy: 0.1570\n","Epoch 22/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.1705The average loss for epoch 21 is    0.12 \n","78/78 [==============================] - 14s 173ms/step - loss: 0.4872 - categorical_accuracy: 0.7115\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1176 - categorical_accuracy: 0.1718\n","Epoch 23/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1076 - categorical_accuracy: 0.1573The average loss for epoch 22 is    0.11 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1075 - categorical_accuracy: 0.1570\n","Epoch 24/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1430 - categorical_accuracy: 0.2091The average loss for epoch 23 is    0.14 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0241 - categorical_accuracy: 0.0353\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1436 - categorical_accuracy: 0.2099\n","Epoch 25/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1075 - categorical_accuracy: 0.1573The average loss for epoch 24 is    0.11 \n","78/78 [==============================] - 11s 137ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 76s 117ms/step - loss: 0.1073 - categorical_accuracy: 0.1570\n","Epoch 26/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1074 - categorical_accuracy: 0.1573The average loss for epoch 25 is    0.11 \n","78/78 [==============================] - 15s 186ms/step - loss: 0.5703 - categorical_accuracy: 0.8349\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1073 - categorical_accuracy: 0.1570\n","Epoch 27/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1074 - categorical_accuracy: 0.1573The average loss for epoch 26 is    0.11 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 119ms/step - loss: 0.1072 - categorical_accuracy: 0.1570\n","Epoch 28/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1287 - categorical_accuracy: 0.1886The average loss for epoch 27 is    0.13 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.1388 - categorical_accuracy: 0.2035\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1295 - categorical_accuracy: 0.1898\n","Epoch 29/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1072 - categorical_accuracy: 0.1573The average loss for epoch 28 is    0.11 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 76s 117ms/step - loss: 0.1071 - categorical_accuracy: 0.1570\n","Epoch 30/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1072 - categorical_accuracy: 0.1573The average loss for epoch 29 is    0.11 \n","78/78 [==============================] - 15s 195ms/step - loss: 0.5231 - categorical_accuracy: 0.7676\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1070 - categorical_accuracy: 0.1570\n","Epoch 31/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1126 - categorical_accuracy: 0.1653The average loss for epoch 30 is    0.11 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1124 - categorical_accuracy: 0.1651\n","Epoch 32/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1146 - categorical_accuracy: 0.1684The average loss for epoch 31 is    0.12 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.2531 - categorical_accuracy: 0.3718\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1155 - categorical_accuracy: 0.1697\n","Epoch 33/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1070 - categorical_accuracy: 0.1573The average loss for epoch 32 is    0.11 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 117ms/step - loss: 0.1068 - categorical_accuracy: 0.1570\n","Epoch 34/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1069 - categorical_accuracy: 0.1573The average loss for epoch 33 is    0.11 \n","78/78 [==============================] - 14s 180ms/step - loss: 0.4021 - categorical_accuracy: 0.5913\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1068 - categorical_accuracy: 0.1570\n","Epoch 35/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1267 - categorical_accuracy: 0.1864The average loss for epoch 34 is    0.13 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1265 - categorical_accuracy: 0.1862\n","Epoch 36/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1068 - categorical_accuracy: 0.1573The average loss for epoch 35 is    0.11 \n","78/78 [==============================] - 12s 151ms/step - loss: 0.3243 - categorical_accuracy: 0.4776\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1066 - categorical_accuracy: 0.1570\n","Epoch 37/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1067 - categorical_accuracy: 0.1573The average loss for epoch 36 is    0.11 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1066 - categorical_accuracy: 0.1570\n","Epoch 38/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1067 - categorical_accuracy: 0.1573The average loss for epoch 37 is    0.11 \n","78/78 [==============================] - 13s 164ms/step - loss: 0.2827 - categorical_accuracy: 0.4167\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1065 - categorical_accuracy: 0.1570\n","Epoch 39/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1406 - categorical_accuracy: 0.2074The average loss for epoch 38 is    0.14 \n","78/78 [==============================] - 11s 147ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1404 - categorical_accuracy: 0.2071\n","Epoch 40/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1065 - categorical_accuracy: 0.1573The average loss for epoch 39 is    0.11 \n","78/78 [==============================] - 13s 161ms/step - loss: 0.3236 - categorical_accuracy: 0.4776\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1064 - categorical_accuracy: 0.1570\n","Epoch 41/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1065 - categorical_accuracy: 0.1573The average loss for epoch 40 is    0.11 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1063 - categorical_accuracy: 0.1570\n","Epoch 42/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1064 - categorical_accuracy: 0.1573The average loss for epoch 41 is    0.11 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.1616 - categorical_accuracy: 0.2388\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1063 - categorical_accuracy: 0.1570\n","Epoch 43/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1547 - categorical_accuracy: 0.2287The average loss for epoch 42 is    0.15 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1544 - categorical_accuracy: 0.2283\n","Epoch 44/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.1573The average loss for epoch 43 is    0.11 \n","78/78 [==============================] - 13s 162ms/step - loss: 0.3184 - categorical_accuracy: 0.4712\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1061 - categorical_accuracy: 0.1570\n","Epoch 45/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1067 - categorical_accuracy: 0.1580The average loss for epoch 44 is    0.11 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 119ms/step - loss: 0.1066 - categorical_accuracy: 0.1578\n","Epoch 46/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1062 - categorical_accuracy: 0.1573The average loss for epoch 45 is    0.11 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0476 - categorical_accuracy: 0.0705\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1060 - categorical_accuracy: 0.1570\n","Epoch 47/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1672 - categorical_accuracy: 0.2479The average loss for epoch 46 is    0.17 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0054 - categorical_accuracy: 0.0080\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1670 - categorical_accuracy: 0.2475\n","Epoch 48/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.1573The average loss for epoch 47 is    0.11 \n","78/78 [==============================] - 13s 163ms/step - loss: 0.2647 - categorical_accuracy: 0.3926\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1058 - categorical_accuracy: 0.1570\n","Epoch 49/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1128 - categorical_accuracy: 0.1674The average loss for epoch 48 is    0.11 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1126 - categorical_accuracy: 0.1672\n","Epoch 50/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1059 - categorical_accuracy: 0.1573The average loss for epoch 49 is    0.11 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1057 - categorical_accuracy: 0.1570\n","Epoch 51/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1630 - categorical_accuracy: 0.2423The average loss for epoch 50 is    0.16 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.0755 - categorical_accuracy: 0.1122\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1638 - categorical_accuracy: 0.2435\n","Epoch 52/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1057 - categorical_accuracy: 0.1573The average loss for epoch 51 is    0.11 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.1465 - categorical_accuracy: 0.2179\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1056 - categorical_accuracy: 0.1570\n","Epoch 53/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1266 - categorical_accuracy: 0.1884The average loss for epoch 52 is    0.13 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1264 - categorical_accuracy: 0.1881\n","Epoch 54/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1056 - categorical_accuracy: 0.1573The average loss for epoch 53 is    0.11 \n","78/78 [==============================] - 11s 137ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 76s 117ms/step - loss: 0.1054 - categorical_accuracy: 0.1570\n","Epoch 55/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1484 - categorical_accuracy: 0.2212The average loss for epoch 54 is    0.15 \n","78/78 [==============================] - 12s 149ms/step - loss: 0.1935 - categorical_accuracy: 0.2885\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1492 - categorical_accuracy: 0.2224\n","Epoch 56/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1054 - categorical_accuracy: 0.1573The average loss for epoch 55 is    0.11 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0355 - categorical_accuracy: 0.0529\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1053 - categorical_accuracy: 0.1570\n","Epoch 57/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1395 - categorical_accuracy: 0.2081The average loss for epoch 56 is    0.14 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1393 - categorical_accuracy: 0.2078\n","Epoch 58/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1053 - categorical_accuracy: 0.1573The average loss for epoch 57 is    0.11 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1051 - categorical_accuracy: 0.1570\n","Epoch 59/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.2001The average loss for epoch 58 is    0.13 \n","78/78 [==============================] - 12s 156ms/step - loss: 0.3110 - categorical_accuracy: 0.4647\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1347 - categorical_accuracy: 0.2013\n","Epoch 60/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1052 - categorical_accuracy: 0.1573The average loss for epoch 59 is    0.11 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1050 - categorical_accuracy: 0.1570\n","Epoch 61/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1432 - categorical_accuracy: 0.2143The average loss for epoch 60 is    0.14 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0011 - categorical_accuracy: 0.0016\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1430 - categorical_accuracy: 0.2140\n","Epoch 62/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1050 - categorical_accuracy: 0.1573The average loss for epoch 61 is    0.10 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1049 - categorical_accuracy: 0.1570\n","Epoch 63/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1194 - categorical_accuracy: 0.1790The average loss for epoch 62 is    0.12 \n","78/78 [==============================] - 13s 166ms/step - loss: 0.4278 - categorical_accuracy: 0.6410\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1203 - categorical_accuracy: 0.1802\n","Epoch 64/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1049 - categorical_accuracy: 0.1573The average loss for epoch 63 is    0.10 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1047 - categorical_accuracy: 0.1570\n","Epoch 65/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1419 - categorical_accuracy: 0.2129The average loss for epoch 64 is    0.14 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0053 - categorical_accuracy: 0.0080\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1421 - categorical_accuracy: 0.2132\n","Epoch 66/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1047 - categorical_accuracy: 0.1573The average loss for epoch 65 is    0.10 \n","78/78 [==============================] - 11s 139ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1046 - categorical_accuracy: 0.1570\n","Epoch 67/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1068 - categorical_accuracy: 0.1605The average loss for epoch 66 is    0.11 \n","78/78 [==============================] - 14s 178ms/step - loss: 0.5323 - categorical_accuracy: 0.7997\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1073 - categorical_accuracy: 0.1612\n","Epoch 68/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1046 - categorical_accuracy: 0.1573The average loss for epoch 67 is    0.10 \n","78/78 [==============================] - 11s 140ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 118ms/step - loss: 0.1045 - categorical_accuracy: 0.1570\n","Epoch 69/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1312 - categorical_accuracy: 0.1974The average loss for epoch 68 is    0.13 \n","78/78 [==============================] - 11s 145ms/step - loss: 0.0863 - categorical_accuracy: 0.1298\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1320 - categorical_accuracy: 0.1986\n","Epoch 70/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1045 - categorical_accuracy: 0.1573The average loss for epoch 69 is    0.10 \n","78/78 [==============================] - 11s 138ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 77s 119ms/step - loss: 0.1043 - categorical_accuracy: 0.1570\n","Epoch 71/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.1573The average loss for epoch 70 is    0.10 \n","78/78 [==============================] - 15s 191ms/step - loss: 0.5405 - categorical_accuracy: 0.8141\n","652/652 [==============================] - 81s 125ms/step - loss: 0.1042 - categorical_accuracy: 0.1570\n","Epoch 72/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.1598The average loss for epoch 71 is    0.11 \n","78/78 [==============================] - 11s 143ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 119ms/step - loss: 0.1058 - categorical_accuracy: 0.1595\n","Epoch 73/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.1763The average loss for epoch 72 is    0.12 \n","78/78 [==============================] - 12s 153ms/step - loss: 0.2030 - categorical_accuracy: 0.3061\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1177 - categorical_accuracy: 0.1775\n","Epoch 74/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1042 - categorical_accuracy: 0.1573The average loss for epoch 73 is    0.10 \n","78/78 [==============================] - 11s 141ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1040 - categorical_accuracy: 0.1570\n","Epoch 75/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1041 - categorical_accuracy: 0.1573The average loss for epoch 74 is    0.10 \n","78/78 [==============================] - 15s 196ms/step - loss: 0.4404 - categorical_accuracy: 0.6651\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1040 - categorical_accuracy: 0.1570\n","Epoch 76/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.1776The average loss for epoch 75 is    0.12 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1173 - categorical_accuracy: 0.1773\n","Epoch 77/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1051 - categorical_accuracy: 0.1590The average loss for epoch 76 is    0.11 \n","78/78 [==============================] - 12s 156ms/step - loss: 0.3010 - categorical_accuracy: 0.4551\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1056 - categorical_accuracy: 0.1597\n","Epoch 78/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1039 - categorical_accuracy: 0.1573The average loss for epoch 77 is    0.10 \n","78/78 [==============================] - 11s 142ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 78s 120ms/step - loss: 0.1038 - categorical_accuracy: 0.1570\n","Epoch 79/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1038 - categorical_accuracy: 0.1573The average loss for epoch 78 is    0.10 \n","78/78 [==============================] - 14s 174ms/step - loss: 0.3228 - categorical_accuracy: 0.4888\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1037 - categorical_accuracy: 0.1570\n","Epoch 80/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1311 - categorical_accuracy: 0.1987The average loss for epoch 79 is    0.13 \n","78/78 [==============================] - 11s 144ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1309 - categorical_accuracy: 0.1984\n","Epoch 81/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1037 - categorical_accuracy: 0.1573The average loss for epoch 80 is    0.10 \n","78/78 [==============================] - 12s 153ms/step - loss: 0.3149 - categorical_accuracy: 0.4776\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1035 - categorical_accuracy: 0.1570\n","Epoch 82/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1036 - categorical_accuracy: 0.1573The average loss for epoch 81 is    0.10 \n","78/78 [==============================] - 12s 158ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1035 - categorical_accuracy: 0.1570\n","Epoch 83/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1035 - categorical_accuracy: 0.1573The average loss for epoch 82 is    0.10 \n","78/78 [==============================] - 12s 159ms/step - loss: 0.2058 - categorical_accuracy: 0.3125\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1034 - categorical_accuracy: 0.1570\n","Epoch 84/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1446 - categorical_accuracy: 0.2199The average loss for epoch 83 is    0.14 \n","78/78 [==============================] - 12s 158ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 86s 132ms/step - loss: 0.1444 - categorical_accuracy: 0.2195\n","Epoch 85/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1033 - categorical_accuracy: 0.1573The average loss for epoch 84 is    0.10 \n","78/78 [==============================] - 14s 175ms/step - loss: 0.3128 - categorical_accuracy: 0.4760\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1032 - categorical_accuracy: 0.1570\n","Epoch 86/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.1575The average loss for epoch 85 is    0.10 \n","78/78 [==============================] - 12s 156ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1032 - categorical_accuracy: 0.1572\n","Epoch 87/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.1573The average loss for epoch 86 is    0.10 \n","78/78 [==============================] - 13s 160ms/step - loss: 0.0915 - categorical_accuracy: 0.1394\n","652/652 [==============================] - 82s 126ms/step - loss: 0.1030 - categorical_accuracy: 0.1570\n","Epoch 88/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1575 - categorical_accuracy: 0.2402The average loss for epoch 87 is    0.16 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.0021 - categorical_accuracy: 0.0032\n","652/652 [==============================] - 84s 129ms/step - loss: 0.1572 - categorical_accuracy: 0.2398\n","Epoch 89/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1030 - categorical_accuracy: 0.1573The average loss for epoch 88 is    0.10 \n","78/78 [==============================] - 13s 167ms/step - loss: 0.2960 - categorical_accuracy: 0.4519\n","652/652 [==============================] - 81s 124ms/step - loss: 0.1028 - categorical_accuracy: 0.1570\n","Epoch 90/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1049 - categorical_accuracy: 0.1603The average loss for epoch 89 is    0.10 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1048 - categorical_accuracy: 0.1601\n","Epoch 91/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1028 - categorical_accuracy: 0.1573The average loss for epoch 90 is    0.10 \n","78/78 [==============================] - 12s 150ms/step - loss: 0.0010 - categorical_accuracy: 0.0016\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1027 - categorical_accuracy: 0.1570\n","Epoch 92/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1639 - categorical_accuracy: 0.2510The average loss for epoch 91 is    0.16 \n","78/78 [==============================] - 12s 153ms/step - loss: 0.0262 - categorical_accuracy: 0.0401\n","652/652 [==============================] - 83s 128ms/step - loss: 0.1645 - categorical_accuracy: 0.2519\n","Epoch 93/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1026 - categorical_accuracy: 0.1573The average loss for epoch 92 is    0.10 \n","78/78 [==============================] - 12s 158ms/step - loss: 0.1893 - categorical_accuracy: 0.2901\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1024 - categorical_accuracy: 0.1570\n","Epoch 94/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1171 - categorical_accuracy: 0.1797The average loss for epoch 93 is    0.12 \n","78/78 [==============================] - 12s 148ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 80s 122ms/step - loss: 0.1170 - categorical_accuracy: 0.1794\n","Epoch 95/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1024 - categorical_accuracy: 0.1573The average loss for epoch 94 is    0.10 \n","78/78 [==============================] - 11s 147ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1022 - categorical_accuracy: 0.1570\n","Epoch 96/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1496 - categorical_accuracy: 0.2300The average loss for epoch 95 is    0.15 \n","78/78 [==============================] - 12s 155ms/step - loss: 0.1397 - categorical_accuracy: 0.2147\n","652/652 [==============================] - 84s 128ms/step - loss: 0.1504 - categorical_accuracy: 0.2312\n","Epoch 97/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1022 - categorical_accuracy: 0.1573The average loss for epoch 96 is    0.10 \n","78/78 [==============================] - 12s 150ms/step - loss: 0.0771 - categorical_accuracy: 0.1186\n","652/652 [==============================] - 79s 122ms/step - loss: 0.1020 - categorical_accuracy: 0.1570\n","Epoch 98/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1300 - categorical_accuracy: 0.2003The average loss for epoch 97 is    0.13 \n","78/78 [==============================] - 12s 152ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 80s 123ms/step - loss: 0.1298 - categorical_accuracy: 0.2000\n","Epoch 99/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1020 - categorical_accuracy: 0.1573The average loss for epoch 98 is    0.10 \n","78/78 [==============================] - 11s 146ms/step - loss: 0.0000e+00 - categorical_accuracy: 0.0000e+00\n","652/652 [==============================] - 79s 121ms/step - loss: 0.1018 - categorical_accuracy: 0.1570\n","Epoch 100/100\n","651/652 [============================>.] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.2089The average loss for epoch 99 is    0.14 \n","78/78 [==============================] - 13s 165ms/step - loss: 0.2532 - categorical_accuracy: 0.3910\n","652/652 [==============================] - 85s 131ms/step - loss: 0.1361 - categorical_accuracy: 0.2101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G54rYFauZa6C","colab_type":"code","outputId":"1519f541-f5ce-4cd8-84d6-5525c1ceafc5","executionInfo":{"status":"ok","timestamp":1590762017186,"user_tz":-180,"elapsed":4626,"user":{"displayName":"Victoria Ilyina","photoUrl":"","userId":"07809839839950640169"}},"colab":{"base_uri":"https://localhost:8080/","height":668}},"source":["%reload_ext tensorboard\n","%tensorboard --logdir logs"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":["ERROR: Failed to launch TensorBoard (exited with 1).\n","Contents of stderr:\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n","    sys.exit(run_main())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 59, in run_main\n","    program.get_default_assets_zip_provider())\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 144, in __init__\n","    self.plugin_loaders = [make_loader(p) for p in plugins]\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 144, in <listcomp>\n","    self.plugin_loaders = [make_loader(p) for p in plugins]\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 143, in make_loader\n","    raise ValueError(\"Not a TBLoader or TBPlugin subclass: %s\" % plugin)\n","ValueError: Not a TBLoader or TBPlugin subclass: <class 'tensorboard_plugin_wit.wit_plugin_loader.WhatIfToolPluginLoader'>"]},"metadata":{"tags":[]}}]}]}